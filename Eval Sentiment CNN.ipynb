{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, [1, 41, 1, 1], strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def add_filter(num_of_words):\n",
    "    W_conv = weight_variable([num_of_words,embedding_size,1,10])\n",
    "    b_conv = bias_variable([10])\n",
    "    h_conv = tf.nn.relu(conv2d(embed_chars_expanded, W_conv) + b_conv)\n",
    "    h_pool = max_pool(h_conv)\n",
    "    \n",
    "    return h_pool, h_conv, W_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21656"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.load('/home/dima/Data/sentiment_vocab.npy')\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21656 300 42 3\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_size = 300\n",
    "sequence_size = 42\n",
    "num_classes = 3\n",
    "\n",
    "print vocab_size, embedding_size, sequence_size, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_x = tf.placeholder(tf.int32, [None, sequence_size], name=\"input_x\")\n",
    "input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "\n",
    "W_embed = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W_embed\")\n",
    "embed_chars = tf.nn.embedding_lookup(W_embed, input_x)\n",
    "embed_chars_expanded = tf.expand_dims(embed_chars, -1)\n",
    "\n",
    "filter = add_filter(2)\n",
    "\n",
    "h_pool = tf.concat(3, [filter[0]])\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, 10])\n",
    "\n",
    "fc_W = tf.Variable(tf.truncated_normal([10, 3], stddev=0.1), name=\"fc_W\")\n",
    "fc_b = tf.Variable(tf.constant(0.1, shape=[3]), name=\"fc_b\")\n",
    "scores = tf.nn.xw_plus_b(h_pool_flat, fc_W, fc_b)\n",
    "predictions = tf.argmax(scores, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/dima/Data/sentiment_manual_data_clean_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5823, 42)\n",
      "(5823, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "tokens_set = list(vocab)\n",
    "pad_index = tokens_set.index('<pad>')\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        text = df['Text_clean'][i]\n",
    "        sentiment = int(df['Sentiment'][i])\n",
    "        \n",
    "        text_tokens = tokenizer.tokenize(text)\n",
    "        d = [tokens_set.index(t) for t in text_tokens if t in tokens_set]\n",
    "        \n",
    "        for i in range(len(d), 42, 1):\n",
    "            d.append(pad_index)\n",
    "            \n",
    "        X.append(d)\n",
    "        d_y = np.zeros(3)\n",
    "        \n",
    "        d_y[sentiment+1] = 1\n",
    "        \n",
    "        Y.append(d_y)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print X.shape\n",
    "print Y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"/home/dima/Models/sentiment_cnn.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predictions.eval(feed_dict={ input_x : X}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_preds = np.argmax(Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.81      0.80      2337\n",
      "          1       0.68      0.71      0.70      2217\n",
      "          2       0.63      0.57      0.60      1269\n",
      "\n",
      "avg / total       0.72      0.72      0.72      5823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(correct_preds, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
