{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "model = Word2Vec.load_word2vec_format('word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from nltk.util import ngrams as nltk_ngrams\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "custom_stopwords = ['rt', '&amp', '#', '', '&amp;', '-', 'amp', '.', 'QQQQQQQQQ', 'll','re','ve']\n",
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_spanish = stopwords.words('spanish')\n",
    "tknzr = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "\n",
    "    # Test Set\n",
    "    start_time = start_exec('Loading test data')\n",
    "    df_test = pd.read_csv('test_data.csv', index_col=False)\n",
    "    X_test = df_test['Text'].apply(preprocess_text)\n",
    "    Y_test = df_test['Sentiment']\n",
    "    stop_exec(start_time)\n",
    "\n",
    "    return X_test, Y_test\n",
    "\n",
    "def preprocess_text(text):\n",
    "    global st\n",
    "    text = str(text)\n",
    "    new_text = text.lower()\n",
    "    new_text = re.sub(r'https://\\S+', 'URL_URL_URL', new_text)\n",
    "    new_text = re.sub(r'http://\\S+', 'URL_URL_URL', new_text)\n",
    "    new_text = re.sub(r'@\\S+', 'USER_MENTION_USER', new_text)\n",
    "    new_text = new_text.replace('rt','')\n",
    "    new_text = new_text.replace('&amp','')\n",
    "    new_text = new_text.replace('&amp','')\n",
    "    new_text = new_text.replace('amp','')\n",
    "    new_text = re.sub('[^a-zA-Z\\s]', '', new_text)\n",
    "    new_text = re.sub(r'\\b\\w{1}\\b', '', new_text)\n",
    "    new_text = re.sub(r'(.)\\1+', r'\\1\\1', new_text)\n",
    "    new_text = new_text.strip()\n",
    "\n",
    "    #words = [st.stem(w) for w in new_text.split() if w not in custom_stopwords and w not in stopwords_english]\n",
    "    #words = [st.stem(w) for w in new_text.split()]\n",
    "\n",
    "    return new_text\n",
    "    return ' '.join(words)\n",
    "\n",
    "def map_sentiment_string(s):\n",
    "    if s == 'positive': return 1\n",
    "    if s == 'negative': return -1\n",
    "    return 0\n",
    "\n",
    "def map_sentiment_float(f):\n",
    "    if f > 0.3: return 1\n",
    "    if f < -0.3: return -1\n",
    "    return 0\n",
    "\n",
    "def map_sentiment_int(i):\n",
    "    i = int(i)\n",
    "    if i == 4: return 1\n",
    "    if i == 0: return -1\n",
    "    return 0\n",
    "\n",
    "def get_tweet_vector(text):\n",
    "    words = text.split()\n",
    "    N = len(words)\n",
    "    vector = np.zeros(300)\n",
    "    \n",
    "    if N > 0:\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                vector += model[word]\n",
    "        vector /= N\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_all.csv')\n",
    "df_test = df_test[df_test[' Sentiment'] != 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['Sentiment_raw'] = df_train['Sentiment']\n",
    "df_train['Sentiment'] = df_train['Sentiment'].apply(map_sentiment_int)\n",
    "df_test['Sentiment'] = df_test[' Sentiment'].apply(map_sentiment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train['Text']\n",
    "Y_train = df_train['Sentiment']\n",
    "X_test = df_test['Text']\n",
    "Y_test = df_test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', LR()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66253101736972708"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for i in range(len(df_train)):\n",
    "    tweet_vector = get_tweet_vector(df_train['Text'][i])\n",
    "    vectors.append(tweet_vector)\n",
    "vectors = np.array(vectors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-63807257fb9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mword2vec_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[1;32m-> 1142\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 54\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "word2vec_clf = LR().fit(vectors, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04052734,  0.0625    , -0.01745605,  0.07861328,  0.03271484,\n",
       "       -0.01263428,  0.00964355,  0.12353516, -0.02148438,  0.15234375,\n",
       "       -0.05834961, -0.10644531,  0.02124023,  0.13574219, -0.13183594,\n",
       "        0.17675781,  0.27148438,  0.13769531, -0.17382812, -0.14160156,\n",
       "       -0.03076172,  0.19628906, -0.03295898,  0.125     ,  0.25390625,\n",
       "        0.12695312, -0.15234375,  0.03198242,  0.01135254, -0.01361084,\n",
       "       -0.12890625,  0.01019287,  0.23925781, -0.08447266,  0.140625  ,\n",
       "        0.13085938, -0.04516602,  0.06494141,  0.02539062,  0.05615234,\n",
       "        0.24609375, -0.20507812,  0.23632812, -0.00860596, -0.02294922,\n",
       "        0.05078125,  0.10644531, -0.03564453,  0.08740234, -0.05712891,\n",
       "        0.08496094,  0.23535156, -0.10107422, -0.03564453, -0.04736328,\n",
       "        0.04736328, -0.14550781, -0.10986328,  0.14746094, -0.23242188,\n",
       "       -0.07275391,  0.19628906, -0.37890625, -0.07226562,  0.04833984,\n",
       "        0.11914062,  0.06103516, -0.12109375, -0.27929688,  0.05200195,\n",
       "        0.04907227, -0.02709961,  0.1328125 ,  0.03369141, -0.32226562,\n",
       "        0.04223633, -0.08789062,  0.15429688,  0.09472656,  0.10351562,\n",
       "       -0.02856445,  0.00128174, -0.00427246,  0.24609375, -0.05957031,\n",
       "       -0.16894531, -0.09619141,  0.16796875,  0.0133667 ,  0.04882812,\n",
       "        0.08349609,  0.06347656, -0.00872803, -0.08642578, -0.03857422,\n",
       "       -0.08251953,  0.15722656,  0.22753906, -0.00762939, -0.19921875,\n",
       "       -0.06347656,  0.12792969, -0.06347656, -0.03027344,  0.0456543 ,\n",
       "        0.06298828, -0.02526855, -0.06787109, -0.01141357, -0.13574219,\n",
       "        0.02978516,  0.10400391, -0.15917969, -0.08447266,  0.29882812,\n",
       "       -0.12597656,  0.11425781, -0.08105469, -0.09082031, -0.07910156,\n",
       "       -0.11181641, -0.09619141,  0.02770996,  0.14257812, -0.26757812,\n",
       "       -0.09375   ,  0.03979492, -0.17871094, -0.02819824,  0.01464844,\n",
       "       -0.31640625, -0.24511719, -0.08935547,  0.09716797, -0.00964355,\n",
       "       -0.14746094,  0.15234375,  0.21582031,  0.05981445,  0.23828125,\n",
       "       -0.05151367,  0.14941406,  0.13574219, -0.03222656, -0.265625  ,\n",
       "       -0.11181641, -0.23046875, -0.140625  ,  0.25585938, -0.15429688,\n",
       "        0.1796875 ,  0.15527344, -0.21582031,  0.36328125, -0.1015625 ,\n",
       "        0.04980469,  0.07177734, -0.14550781, -0.03198242,  0.00952148,\n",
       "       -0.12109375,  0.12109375,  0.09765625,  0.07763672,  0.3203125 ,\n",
       "       -0.22265625, -0.08447266, -0.10742188,  0.11279297, -0.13867188,\n",
       "       -0.21875   ,  0.0145874 ,  0.13378906, -0.00921631,  0.00921631,\n",
       "        0.16894531,  0.16894531, -0.078125  , -0.00665283,  0.03735352,\n",
       "       -0.10888672, -0.25390625,  0.01452637, -0.09716797, -0.19628906,\n",
       "       -0.01782227, -0.28125   , -0.02050781, -0.02905273, -0.09375   ,\n",
       "       -0.17675781,  0.21484375, -0.05224609, -0.11572266, -0.01977539,\n",
       "       -0.10839844, -0.01342773, -0.15332031, -0.140625  , -0.11816406,\n",
       "        0.09228516,  0.109375  ,  0.05761719, -0.03466797,  0.03564453,\n",
       "       -0.12011719, -0.14257812, -0.00072479, -0.06689453,  0.11914062,\n",
       "       -0.10449219,  0.07861328, -0.12792969,  0.09570312, -0.00817871,\n",
       "        0.07128906,  0.20703125, -0.03149414,  0.09570312,  0.17285156,\n",
       "       -0.07958984, -0.02429199, -0.07519531, -0.07568359,  0.09521484,\n",
       "       -0.06494141, -0.00689697, -0.09033203,  0.03100586,  0.19921875,\n",
       "       -0.10644531, -0.11474609,  0.18652344, -0.05078125,  0.0859375 ,\n",
       "        0.00128937, -0.18847656, -0.20019531, -0.02832031,  0.11328125,\n",
       "        0.25976562,  0.22070312,  0.04101562,  0.00171661,  0.07568359,\n",
       "       -0.01196289,  0.0177002 , -0.05883789, -0.25976562, -0.234375  ,\n",
       "       -0.04956055,  0.25976562,  0.15332031,  0.15136719,  0.08300781,\n",
       "       -0.15527344,  0.04931641,  0.07519531, -0.05078125, -0.1328125 ,\n",
       "       -0.13574219,  0.04199219, -0.14257812,  0.02099609,  0.07861328,\n",
       "        0.01611328,  0.01623535, -0.21582031,  0.01599121, -0.04882812,\n",
       "       -0.02404785,  0.13476562,  0.08496094, -0.01196289,  0.10009766,\n",
       "       -0.13867188,  0.08056641, -0.22070312, -0.12011719,  0.18945312,\n",
       "        0.05444336, -0.05053711,  0.00147247,  0.14160156, -0.06494141,\n",
       "       -0.05566406, -0.09033203, -0.0267334 , -0.10498047,  0.02416992,\n",
       "        0.01422119,  0.1875    , -0.16503906,  0.01538086, -0.04174805,\n",
       "        0.05444336, -0.01184082, -0.15625   ,  0.00193024, -0.06982422], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = None\n",
    "vectors_array = None\n",
    "gc.collect()\n",
    "model['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
